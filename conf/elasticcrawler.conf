#
# Elasticsearch host name.
#
ES_HOST=127.0.0.1

#
# Elasticsearch host port.
#
ES_PORT=9200

#
# Elasticsearch index name.
#
ES_INDEX=web

#
# Allowed protocols for contnet fetching
#
ALLOWED_PROTOCOLS=http,https

#
# HTTP User-Agent string to send to the HTTP server.
#
HTTP_USER_AGENT="seebot/2.0 (+http://www.seegnify.com/bot)"

#
# Minimum delay between consecutive requests to the same host in seconds.
#
HOST_ACCESS_DELAY=10

#
# Maximum download size in bytes per single fetch. -1 to allow unlimited size.
#
MAX_FETCH_SIZE=2000000

#
# Maximum time in seconds that you allow the fetch operation to take.
#
MAX_FETCH_TIME=60

#
# Maximum time in seconds that you allow the parse operation to take.
#
MAX_PARSE_TIME=60

#
# Exclude private LAN addresses (ie: 192.168.X.X, 10.X.X.X) from crawling.
#
EXCLUDE_PRIVATE_HOSTS=true

#
# Exclude single-word hosts (ie: http://flip/, http://flap/) from crawling.
#
EXCLUDE_SINGLE_HOSTS=true

#
# Exclude file types from fetching.
#
EXCLUDE_FILE_TYPES=\
jpg,jpeg,png,bmp,gif,tif,tiff,ico,\
wav,flac,mp3,m3u,wma,wmx,aac,asx\
mp4,m4v,vob,mpeg,mpg,mov,mkv,avi\
js,css,xml,svg,exe,dll,dmg,com

#
# Tika application jar used for content extraction.
#
TIKA_PARSER_JAR=/opt/apache-tika/tika-app-1.6.jar

#
# Content parser port to launch on demand via jar defined by TIKA_PARSER_JAR.
#
TIKA_PARSER_PORT=9900

#
# Log folder for persistent logs.
#
LOGS_DIRECTORY=/var/elasticcrawler/logs

#
# Maximum number of jobs allowed to run.
#
MAX_JOB_COUNT=10


